# ğŸ•¸ï¸ Web Scraper de Marketplaces â€“ Python

Este projeto tem como objetivo **mapear e coletar informaÃ§Ãµes de produtos em marketplaces online**, incluindo **preÃ§os**, **avaliaÃ§Ãµes** e **valores de entrega**.  
O scraper foi desenvolvido em **Python**, utilizando **Selenium** e **BeautifulSoup**, e os dados coletados sÃ£o tratados e exportados para planilhas atravÃ©s do **Pandas**.

---

## ğŸ¯ Objetivo

Automatizar a **coleta e anÃ¡lise de dados de e-commerce**, permitindo comparar produtos entre diferentes marketplaces e gerar insights sobre:
- ğŸ’° VariaÃ§Ã£o de preÃ§os  
- â­ AvaliaÃ§Ãµes mÃ©dias  
- ğŸšš Custos e prazos de entrega  

---

## âš™ï¸ Funcionalidades

- ğŸ” Coleta automÃ¡tica de informaÃ§Ãµes de produtos  
- ğŸ·ï¸ ExtraÃ§Ã£o de preÃ§o, nome, avaliaÃ§Ã£o e valor de frete  
- ğŸ•“ Esperas dinÃ¢micas com Selenium para pÃ¡ginas com JavaScript  
- ğŸ’¾ Armazenamento em planilhas `.csv` ou `.xlsx`  
- ğŸ§¹ Tratamento e limpeza de dados com Pandas  
- ğŸ” ExecuÃ§Ã£o programÃ¡vel (para coleta periÃ³dica)

---

## ğŸ§  Tecnologias Utilizadas

| Tecnologia | FunÃ§Ã£o |
|-------------|--------|
| **Python 3.10+** | Linguagem principal |
| **Selenium** | NavegaÃ§Ã£o automatizada e scraping dinÃ¢mico |
| **BeautifulSoup (bs4)** | ExtraÃ§Ã£o e parsing de HTML |
| **Pandas** | EstruturaÃ§Ã£o e exportaÃ§Ã£o dos dados |
| **WebDriver (Chrome/Firefox)** | AutomaÃ§Ã£o do navegador |
| **time / re / os / json** | UtilitÃ¡rios internos para controle e tratamento |

---

---

## ğŸ§© Exemplo de Dados Coletados

| Produto | PreÃ§o | AvaliaÃ§Ã£o | Frete | Marketplace |
|----------|--------|------------|--------|--------------|
| Fone Bluetooth XYZ | R$ 89,90 | â­ 4.6 | GrÃ¡tis | Amazon |
| Teclado MecÃ¢nico ABC | R$ 219,00 | â­ 4.8 | R$ 15,00 | Mercado Livre |
| Monitor 24â€ UltraWide | R$ 799,90 | â­ 4.5 | R$ 25,00 | Magazine Luiza |

---

## ğŸ’» Como Executar o Projeto

### ğŸ”¹ 1. Clonar o repositÃ³rio
```bash
git clone https://github.com/seu-usuario/webscraper-marketplaces.git
cd webscraper-marketplaces

3. Instalar dependÃªncias
pip install -r requirements.txt

4- Executar o scraper
python scraper.py
Â´Â´Â´
